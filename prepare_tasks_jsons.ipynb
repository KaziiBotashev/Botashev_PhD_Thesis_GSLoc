{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "from os import makedirs\n",
    "from gaussian_renderer import render_lie, render_qtvec\n",
    "import torchvision\n",
    "from utils.general_utils import safe_state\n",
    "from argparse import ArgumentParser\n",
    "from arguments import ModelParams, PipelineParams, get_combined_args, pose_estimation_params\n",
    "from gaussian_renderer import GaussianModel\n",
    "from utils.image_utils import psnr\n",
    "from utils.loss_utils import EdgeDetection\n",
    "import numpy as np\n",
    "from utils.loss_utils import l1_loss, ssim, l2_loss\n",
    "from copy import deepcopy\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity as LPIPS\n",
    "import pypose as pp\n",
    "\n",
    "from scene.dataset_readers import readColmapSceneInfo\n",
    "from utils.camera_utils import loadCam\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import math\n",
    "from diff_gaussian_rasterization_lie_pp import GaussianRasterizationSettings, GaussianRasterizer\n",
    "from scene.gaussian_model import GaussianModel\n",
    "from utils.sh_utils import eval_sh\n",
    "\n",
    "import pickle\n",
    "\n",
    "from scene.dataset_readers import CameraInfo\n",
    "from PIL import Image\n",
    "import mrob\n",
    "import open3d as o3d\n",
    "\n",
    "from arguments import  pose_estimation_params\n",
    "from utils.general_utils import get_expon_lr_func\n",
    "import cv2\n",
    "from glob import glob\n",
    "import copy\n",
    "import json\n",
    "\n",
    "def get_number_of_max_iou_iters(num, max_iters=16):\n",
    "    return num if num < max_iters else max_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 40.60it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 42.59it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 69.59it/s] \n",
      "100%|██████████| 32/32 [00:00<00:00, 53.90it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 70.33it/s] \n"
     ]
    }
   ],
   "source": [
    "tasks_root = '/mnt/sdb1/home/kbotashev/iros_paper/replica_dataset_1/results_res4/tasks'\n",
    "number_of_max_iou_iters = 8\n",
    "\n",
    "for room in ['apartment_0', 'apartment_1', 'office_0', 'office_2', 'office_4']:\n",
    "    for camera_type in ['lietorch']:\n",
    "    # for camera_type in ['lietorch', 'qtvec']:\n",
    "        room_task_info = {  \n",
    "                            'room_name':room,\n",
    "                            # 'camera_type':camera_type,\n",
    "                            # # 'camera_type':'qtvec',\n",
    "                            # 'solving_method':'vanilla',\n",
    "                            # 'solving_method_args': None,\n",
    "                            # 'loss_type':'l1',\n",
    "                            # 'optimizer_type':'adam',\n",
    "                            # 'init_render_resolution':2,\n",
    "                            # 'iterations':2000,\n",
    "                            # 'exit_psnr_parameter':1e-4,\n",
    "                            # 'pose_lr_init':0.01,\n",
    "                            # 'pose_lr_final':1e-5,\n",
    "                            # 'pose_lr_delay_steps':0,\n",
    "                            # 'pose_lr_delay_mult':0,\n",
    "                            'start_frame':0,\n",
    "                            'last_frame':32,\n",
    "                            'experiments_base_dir':'/mnt/sdb1/home/kbotashev/iros_paper/replica_dataset_1/'\n",
    "                        }\n",
    "\n",
    "        ply_path = os.path.join(room_task_info['experiments_base_dir'], \n",
    "                                'output', room_task_info['room_name'], \n",
    "                                'point_cloud/iteration_40000/point_cloud.ply')\n",
    "\n",
    "        frames_info_pickle_paths = sorted(glob(os.path.join(room_task_info['experiments_base_dir'], \n",
    "                                        'scenes', room_task_info['room_name'], \n",
    "                                        room_task_info['room_name']+'_task', 'images_pairs_light/*.pickle')))\n",
    "\n",
    "        frames_info_full = {}\n",
    "        frames_results_full = copy.copy(room_task_info)\n",
    "        frames_results_full['results'] = {}\n",
    "\n",
    "        for frames_info_pickle_path in tqdm(frames_info_pickle_paths[room_task_info['start_frame']:room_task_info['last_frame']]):\n",
    "            frame_name = frames_info_pickle_path.split('/')[-1].split('.pickle')[0]\n",
    "            frames_results_full['results'][frame_name] = {}\n",
    "            frames_results_full['results'][frame_name]['valid_iou_bins_indices'] = {}\n",
    "            with open(frames_info_pickle_path, 'rb') as handle:\n",
    "                frames_info_full[frame_name] = pickle.load(handle)\n",
    "            for iou_key in frames_info_full[frame_name]['frames']['init_frames_iou_bins'].keys():\n",
    "                frames_results_full['results'][frame_name]['valid_iou_bins_indices'][iou_key] = []\n",
    "                for idx, frame in enumerate(frames_info_full[frame_name]['frames']['init_frames_iou_bins'][iou_key]):\n",
    "                    if frame['black_pixels_ratio'] < 0.1:\n",
    "                        frames_results_full['results'][frame_name]['valid_iou_bins_indices'][iou_key].append(idx)\n",
    "\n",
    "            frame_iou_stats = frames_info_full[frame_name]['frames']['init_frames_iou_bins_stats']\n",
    "            iou_bins = [0.05, 0.1, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.50, 0.65]\n",
    "            # iou_bins = frame_iou_stats.keys()\n",
    "            # frames_results_full['results'][frame_name]['desired_frame_result_stats'] = {iou:get_number_of_max_iou_iters(frame_iou_stats[iou]) for iou in iou_bins}\n",
    "            # frames_results_full['results'][frame_name]['current_frame_result_stats'] = {iou:0 for iou in iou_bins}\n",
    "            # frames_results_full['results'][frame_name]['frame_results'] = {iou:{} for iou in iou_bins}\n",
    "\n",
    "        for frame_name in frames_results_full['results'].keys():\n",
    "            stats = frames_results_full['results'][frame_name]['valid_iou_bins_indices']\n",
    "            for iou in iou_bins:\n",
    "                for init_id in stats[iou][:number_of_max_iou_iters]:\n",
    "                    task_info = copy.copy(room_task_info)\n",
    "                    del task_info['start_frame']\n",
    "                    del task_info['last_frame']\n",
    "                    pickle_path = os.path.join(room_task_info['experiments_base_dir'], \n",
    "                                        'scenes', room_task_info['room_name'], \n",
    "                                        room_task_info['room_name']+'_task', 'images_pairs_light',  frame_name + '.pickle')\n",
    "                    task_info['ply_path'] = ply_path\n",
    "                    task_info['pickle_path'] = pickle_path\n",
    "                    task_info['init_id'] = init_id\n",
    "                    task_info['iou_bin'] = iou\n",
    "                    task_info['frame_name'] = frame_name\n",
    "                    \n",
    "                    room_task_dir = os.path.join(tasks_root, task_info['room_name'])\n",
    "                    # experiment_task_dir = os.path.join(room_task_dir, \n",
    "                    #                                 str(task_info['camera_type']) + '_' + \n",
    "                    #                                 str(task_info['loss_type']) + '_' + \n",
    "                    #                                 str(task_info['optimizer_type']) + '_' + \n",
    "                    #                                 str(task_info['init_render_resolution']) + '_' + \n",
    "                    #                                 str(task_info['iterations']) + '_' + \n",
    "                    #                                 str(task_info['pose_lr_init']) + '_' + \n",
    "                    #                                 str(task_info['pose_lr_final']) + '_' + \n",
    "                    #                                 str(task_info['pose_lr_delay_steps']) + '_' + \n",
    "                    #                                 str(task_info['pose_lr_delay_mult']) + '_' + \n",
    "                    #                                 str(task_info['exit_psnr_parameter']) + '_' + \n",
    "                    #                                 str(task_info['solving_method']) + '_' + \n",
    "                    #                                 str(task_info['solving_method_args']))\n",
    "                    frame_experiment_task_dir = os.path.join(room_task_dir, frame_name, ('%.2f'%iou).replace('.', ''))\n",
    "\n",
    "                    os.makedirs(frame_experiment_task_dir, exist_ok=True)\n",
    "\n",
    "                    id_iou_frame_json_name = str(init_id).zfill(3) + '_' + ('%.2f'%iou).replace('.', '') + '_' +  frame_name + '.json'\n",
    "\n",
    "                    json_path = os.path.join(frame_experiment_task_dir, id_iou_frame_json_name)\n",
    "\n",
    "                    with open(json_path, 'w') as f:\n",
    "                        json.dump(task_info, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m step_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      2\u001b[0m room_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapartment_0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffice_0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffice_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapartment_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffice_4\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m frame_num \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m      4\u001b[0m camera_types \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlietorch\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m solving_methods \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoarse\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "step_frame = 1\n",
    "room_names = ['apartment_0', 'office_0', 'office_2', 'apartment_1', 'office_4']\n",
    "frame_num = np.arange(32)\n",
    "camera_types = ['lietorch']\n",
    "solving_methods = ['coarse']\n",
    "init_render_resolutions = [2]\n",
    "\n",
    "# step_frame = 1\n",
    "# room_names = ['apartment_0', 'office_0', 'office_2', 'apartment_1', 'office_4']\n",
    "# frame_num = np.arange(32)\n",
    "# camera_types = ['qtvec', 'lietorch']\n",
    "# solving_methods = ['vanilla', 'coarse']\n",
    "\n",
    "# loss_types=['l1']\n",
    "# optimizer_types=['adam']\n",
    "# init_render_resolutions=[2]\n",
    "# iterations_params=[2000]\n",
    "# exit_psnr_parameters=[5e-5],\n",
    "# pose_lrs_init=[0.01]\n",
    "# pose_lrs_final=[1e-5]\n",
    "# pose_lrs_delay_steps=[0]\n",
    "# pose_lrs_delay_mult=[0]\n",
    "\n",
    "# solving_methods_args = [{ \n",
    "#                         'max_scale':2,\n",
    "#                         'num_tries':5,\n",
    "#                         'blur_2d_c2f_kernel_size':201,\n",
    "#                         'blur_2d_c2f_schedule':[0.05, 0.025, 0.0125, 0.00625, 0.00625, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#                        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "for start_frame in frame_num:\n",
    "    for camera_type in camera_types:\n",
    "            for room_name in room_names:\n",
    "                for solving_method in solving_methods:\n",
    "                    for init_render_resolution in init_render_resolutions:\n",
    "                        combinations.append([room_name, start_frame, start_frame+1, camera_type, solving_method, init_render_resolution])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinations += combinations[-16:]\n",
    "combinations = np.array(combinations).reshape(8,2, 20, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_bash_dir = '/mnt/sdb1/home/kbotashev/iros_paper/replica_dataset_1/results_res4/input_bashs'\n",
    "min_gpu = 0\n",
    "terminal_lines = []\n",
    "for gpu_id, combo6 in enumerate(combinations):\n",
    "    for gpu_sub_id, combo3 in enumerate(combo6):\n",
    "        lines = []\n",
    "        for combo in combo3:\n",
    "            lines.append('\\nCUDA_VISIBLE_DEVICES='+str(gpu_id+min_gpu) + \n",
    "                  ', /mnt/sdb1/home/kbotashev/anaconda3/envs/gs102/bin/python' + \n",
    "                  ' /mnt/sdb1/home/kbotashev/mip-nerf_projects/gaussian_splatting_original/gaussian-splatting/solve_pose_estimation.py ' + \\\n",
    "                    '--room_name='+combo[0] + ' --start_frame='+combo[1] + ' --end_frame='+combo[2] + \\\n",
    "                    ' --camera_type='+combo[3] + ' --solving_method='+combo[4] + ' --init_render_resolution='+combo[5])\n",
    "        f = open(os.path.join(output_bash_dir, str(gpu_id+min_gpu) + '_' + str(gpu_sub_id) + \".sh\"), \"w\")\n",
    "        f.writelines(lines)\n",
    "        f.close()\n",
    "        terminal_lines.append('\\nnohup bash ' + os.path.join(output_bash_dir, str(gpu_id+min_gpu) + \n",
    "                                                           '_' + str(gpu_sub_id) + \".sh\") + ' > ' + \n",
    "                                                           os.path.join(output_bash_dir, str(gpu_id+min_gpu) + '_' + str(gpu_sub_id) + '_log.out &'))\n",
    "\n",
    "f = open(os.path.join(output_bash_dir, \"run_bashes.sh\"), \"w\")\n",
    "f.writelines(terminal_lines)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68408262454435"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob('/mnt/sdb1/home/kbotashev/iros_paper/replica_dataset_1/results/solutions/qtvec_l1_adam_2_2000_0.01_1e-05_0_0_0.0001_vanilla_None/*/*/*/*_1.pickle'))/len(glob('/mnt/sdb1/home/kbotashev/iros_paper/replica_dataset_1/results/solutions/qtvec_l1_adam_2_2000_0.01_1e-05_0_0_0.0001_vanilla_None/*/*/*/*.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42594091460946987"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob('/mnt/sdb1/home/kbotashev/iros_paper/replica_dataset_1/results/solutions/lietorch_l1_adam_2_2000_0.01_1e-05_0_0_0.0001_vanilla_None/*/*/*/*_1.pickle'))/len(glob('/mnt/sdb1/home/kbotashev/iros_paper/replica_dataset_1/results/solutions/lietorch_l1_adam_2_2000_0.01_1e-05_0_0_0.0001_vanilla_None/*/*/*/*.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob('/mnt/sdb1/home/kbotashev/iros_paper/replica_dataset/results/tasks/*/*/*/*.json'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs102",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

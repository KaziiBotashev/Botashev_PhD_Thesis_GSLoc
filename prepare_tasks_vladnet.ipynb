{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d import io\n",
    "import torch\n",
    "from pytorch3d.renderer.cameras import FoVPerspectiveCameras, PerspectiveCameras\n",
    "from pytorch3d.renderer.points.rasterizer import PointsRasterizer, PointsRasterizationSettings\n",
    "from pytorch3d.structures import Pointclouds\n",
    "from pytorch3d.utils import cameras_from_opencv_projection \n",
    "from pytorch3d.renderer import (\n",
    "    PointsRenderer,\n",
    "    NormWeightedCompositor\n",
    ")\n",
    "\n",
    "from scene.dataset_readers import readColmapSceneInfo\n",
    "from utils.camera_utils import loadCam\n",
    "from collections import namedtuple\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mrob\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import copy\n",
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_point_cloud_camera_fraction(R, tvec, fx, fy, cx, cy, height, width, points, build_image=False):\n",
    "    camera_matrix = torch.tensor([[fx, 0, cx],\n",
    "                               [0, fy, cy],\n",
    "                               [0,0,1]])\n",
    "    # R = [camera.R for camera in cameras]\n",
    "    # tvec = [camera.T for camera in cameras]\n",
    "\n",
    "    camera_p3d = cameras_from_opencv_projection(R = torch.tensor(np.array(R)).unsqueeze(0).float(), \n",
    "                                                tvec = torch.tensor(np.array(tvec)).unsqueeze(0).float(), \n",
    "                                                camera_matrix = camera_matrix.unsqueeze(0).float(),\n",
    "                                                image_size = torch.tensor([height, \n",
    "                                                                          width]).unsqueeze(0).float())\n",
    "    \n",
    "    raster_settings = PointsRasterizationSettings(\n",
    "                    image_size=(height, \n",
    "                                width), \n",
    "                    radius = 0.025,\n",
    "                    points_per_pixel = 1 \n",
    "                    )\n",
    "\n",
    "    # Create a points rasterizer\n",
    "    \n",
    "\n",
    "    rasterizer = PointsRasterizer(cameras=camera_p3d.cuda(), raster_settings=raster_settings)\n",
    "    rasterized = rasterizer(points)\n",
    "\n",
    "    image = None\n",
    "    if build_image:\n",
    "        renderer = PointsRenderer(\n",
    "            rasterizer=rasterizer,\n",
    "            # Pass in background_color to the alpha compositor, setting the background color \n",
    "            # to the 3 item tuple, representing rgb on a scale of 0 -> 1, in this case blue\n",
    "            compositor=NormWeightedCompositor()\n",
    "        )\n",
    "\n",
    "        image = renderer(points)\n",
    "\n",
    "    fraction_set = set(torch.unique(rasterized.idx)[1:].tolist())\n",
    "\n",
    "    return fraction_set, image\n",
    "\n",
    "def compute_iou_2sets(set0, set1):\n",
    "\n",
    "    intersection_indices = set0.intersection(set1)\n",
    "    union_indices = set0.union(set1)\n",
    "    iou = len(intersection_indices)/len(union_indices)\n",
    "\n",
    "    return iou, list(intersection_indices), list(union_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sparse = pd.read_csv('/mnt/sdb1/home/kbotashev/iros_paper/ibr_dataset/results/sparse_results_top5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading camera 263/263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:17<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---FINISHED---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "room_name = 'drjohnson'\n",
    "ply_path_base = \"/mnt/sdb1/home/kbotashev/iros_paper/ibr_dataset/scenes/$roomname$/$roomname$_base/sparse/0/points3D.ply\"\n",
    "ply_path = ply_path_base.replace('$roomname$', room_name)\n",
    "task_dir_path = os.path.join(ply_path.replace('_base/sparse/0/points3D.ply', '_task'))\n",
    "base_dir_path = os.path.join(ply_path.replace('_base/sparse/0/points3D.ply', '_base'))\n",
    "\n",
    "# scene_info_task = readColmapSceneInfo(task_dir_path, 'images', eval=False)\n",
    "scene_info_base = readColmapSceneInfo(base_dir_path, 'images', eval=True)\n",
    "\n",
    "pcd_o3d = o3d.io.read_point_cloud(ply_path)\n",
    "pcd_o3d = pcd_o3d.voxel_down_sample(voxel_size=0.025)\n",
    "points_tensor = torch.tensor(np.asarray(pcd_o3d.points)).unsqueeze(0).cuda().float()\n",
    "colors_tensor = torch.tensor(np.asarray(pcd_o3d.colors)).unsqueeze(0).cuda().float()\n",
    "points = Pointclouds(points_tensor, features=colors_tensor)\n",
    "\n",
    "args = namedtuple('args', ['resolution', 'data_device'])\n",
    "args = args(1, 'cuda:1')\n",
    "pipe = namedtuple('pipe', ['convert_SHs_python', 'compute_cov3D_python', 'debug'])\n",
    "pipe = pipe(False, False, False)\n",
    "bg_color = [0, 0, 0]\n",
    "background = torch.tensor(bg_color, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "ids = np.arange(len(scene_info_base.test_cameras))\n",
    "\n",
    "data_sparse_room = data_sparse[data_sparse['room_name'] == room_name]\n",
    "\n",
    "for id in tqdm(ids):\n",
    "    cam_info = scene_info_base.test_cameras[id]\n",
    "    camera = loadCam(args=args, id = id, cam_info=cam_info, resolution_scale=1)\n",
    "\n",
    "    height = camera.image_height\n",
    "    width = camera.image_width\n",
    "    fx = camera.fx\n",
    "    fy = camera.fy\n",
    "    cx = camera.cx\n",
    "    cy = camera.cy\n",
    "    scene_results = {}\n",
    "    scene_results['point_cloud_path'] = ply_path\n",
    "    scene_results['scene'] = ply_path.split('/')[-5]\n",
    "    scene_results['img_name'] = cam_info.image_name\n",
    "    frame_results = {0:{}}\n",
    "\n",
    "    T_gt = mrob.geometry.SE3(mrob.geometry.SO3(camera.R), camera.T)\n",
    "    set_gt, _ = compute_point_cloud_camera_fraction(**{'R':T_gt.R(), 'tvec':T_gt.t(), \n",
    "                            \"fx\":fx, 'fy':fy, \n",
    "                            'cx':cy, 'cy':cy, \n",
    "                            'height':height, 'width':width, \n",
    "                            'points':points})\n",
    "    \n",
    "    row = data_sparse_room[data_sparse_room['frame_id'] == cam_info.image_name]\n",
    "\n",
    "    top5_frames = row['top_k_refs'].item().replace('[', '').replace('\\n', '').replace(']', '').replace(\"'\", '').split(' ')[:5]\n",
    "\n",
    "    init_ids = [topk_path.split('/')[-1].split('.jpg')[0] for topk_path in top5_frames]\n",
    "\n",
    "    scene_info_base_train_cameras = {scene_info_base.train_cameras[i].image_name:scene_info_base.train_cameras[i] for i in range(len(scene_info_base.train_cameras))}\n",
    "\n",
    "    for int_id, init_id in enumerate(init_ids):\n",
    "\n",
    "        camera_init = loadCam(args=args, id = int_id, cam_info=scene_info_base_train_cameras[init_id], resolution_scale=1)\n",
    "\n",
    "        set_init, image_init = compute_point_cloud_camera_fraction(**{'R':camera_init.R, 'tvec':camera_init.T, \n",
    "                        \"fx\":fx, 'fy':fy, \n",
    "                        'cx':cy, 'cy':cy, \n",
    "                        'height':height, 'width':width, \n",
    "                        'points':points,\n",
    "                        'build_image':True})\n",
    "        \n",
    "        norm_image = cv2.normalize(image_init[0].cpu().numpy(), None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "\n",
    "        norm_image = norm_image.astype(np.uint8)\n",
    "\n",
    "        iou, intersection_indices, union_indices = compute_iou_2sets(set_gt, set_init)\n",
    "\n",
    "        frame_results[0][init_id] = {'R_init':camera_init.R,\n",
    "                                'T_init':camera_init.T,\n",
    "                                'iou':iou,\n",
    "                                'init_fraction_set_idx':list(set_init),\n",
    "                                'intersection_idx':intersection_indices,\n",
    "                                'union_idx':union_indices,\n",
    "                                'init_image':norm_image,\n",
    "                                'init_base_id':init_id,\n",
    "                                'black_pixels_ratio':0\n",
    "                                                        }\n",
    "                \n",
    "        # init_frames_stats = {key:len(frame_results[key]) for key in frame_results.keys()}    \n",
    "    \n",
    "    scene_results['frames'] = {'img_path':cam_info.image_path,\n",
    "                                'R':cam_info.R,\n",
    "                                'T':cam_info.T,\n",
    "                                'uid':id,\n",
    "                                'FovY':cam_info.FovY,\n",
    "                                'FovX':cam_info.FovX,\n",
    "                                'image':np.array(cam_info.image),\n",
    "                                'width':cam_info.width,\n",
    "                                'height':cam_info.height,\n",
    "                                'qvec':cam_info.qvec,\n",
    "                                'cx':cam_info.cx,\n",
    "                                'cy':cam_info.cy,\n",
    "                                'gt_fraction_set_idx':list(set_gt),\n",
    "                                'init_frames_iou_bins':frame_results,\n",
    "                                # 'init_frames_iou_bins_stats':init_frames_stats\n",
    "                                }\n",
    "    \n",
    "    os.makedirs(os.path.join(task_dir_path, 'task-base_images_pairs'), exist_ok = True)\n",
    "    with open(os.path.join(task_dir_path, 'task-base_images_pairs', cam_info.image_name + '.pickle'), 'wb') as handle:\n",
    "        pickle.dump(scene_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print('---FINISHED---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 91.56it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 105.53it/s]\n"
     ]
    }
   ],
   "source": [
    "tasks_root = '/mnt/sdb1/home/kbotashev/iros_paper/ibr_dataset/results/tasks'\n",
    "\n",
    "for room in ['drjohnson', 'playroom']:\n",
    "    for camera_type in ['lietorch']:\n",
    "    # for camera_type in ['lietorch', 'qtvec']:\n",
    "        room_task_info = {  \n",
    "                            'room_name':room,\n",
    "                            # 'camera_type':camera_type,\n",
    "                            # # 'camera_type':'qtvec',\n",
    "                            # 'solving_method':'vanilla',\n",
    "                            # 'solving_method_args': None,\n",
    "                            # 'loss_type':'l1',\n",
    "                            # 'optimizer_type':'adam',\n",
    "                            # 'init_render_resolution':2,\n",
    "                            # 'iterations':2000,\n",
    "                            # 'exit_psnr_parameter':1e-4,\n",
    "                            # 'pose_lr_init':0.01,\n",
    "                            # 'pose_lr_final':1e-5,\n",
    "                            # 'pose_lr_delay_steps':0,\n",
    "                            # 'pose_lr_delay_mult':0,\n",
    "                            'start_frame':0,\n",
    "                            'last_frame':32,\n",
    "                            'experiments_base_dir':'/mnt/sdb1/home/kbotashev/iros_paper/ibr_dataset/'\n",
    "                        }\n",
    "\n",
    "        ply_path = os.path.join(room_task_info['experiments_base_dir'], \n",
    "                                'output', room_task_info['room_name'], \n",
    "                                'point_cloud/iteration_40000/point_cloud.ply')\n",
    "\n",
    "        frames_info_pickle_paths = sorted(glob(os.path.join(room_task_info['experiments_base_dir'], \n",
    "                                        'scenes', room_task_info['room_name'], \n",
    "                                        room_task_info['room_name']+'_task', 'task-base_images_pairs/*.pickle')))\n",
    "\n",
    "        for frames_info_pickle_path in tqdm(frames_info_pickle_paths[room_task_info['start_frame']:room_task_info['last_frame']]):\n",
    "            frame_name = frames_info_pickle_path.split('/')[-1].split('.pickle')[0]\n",
    "\n",
    "            with open(frames_info_pickle_path, 'rb') as handle:\n",
    "                frame_info = pickle.load(handle)\n",
    "\n",
    "            for init_id in frame_info['frames']['init_frames_iou_bins'][0].keys():\n",
    "                task_info = copy.copy(room_task_info)\n",
    "                del task_info['start_frame']\n",
    "                del task_info['last_frame']\n",
    "\n",
    "                pickle_path = os.path.join(room_task_info['experiments_base_dir'], \n",
    "                                    'scenes', room_task_info['room_name'], \n",
    "                                    room_task_info['room_name']+'_task',\n",
    "                                    'task-base_images_pairs',  frame_name + '.pickle')\n",
    "                \n",
    "                task_info['ply_path'] = ply_path\n",
    "                task_info['pickle_path'] = pickle_path\n",
    "                task_info['init_id'] = init_id\n",
    "                task_info['iou_bin'] = 0\n",
    "                task_info['frame_name'] = frame_name\n",
    "\n",
    "                room_task_dir = os.path.join(tasks_root, task_info['room_name'])\n",
    "\n",
    "                iou = frame_info['frames']['init_frames_iou_bins'][0][init_id]['iou']\n",
    "\n",
    "                frame_experiment_task_dir = os.path.join(room_task_dir, frame_name, ('%.2f'%0).replace('.', ''))\n",
    "\n",
    "                os.makedirs(frame_experiment_task_dir, exist_ok=True)\n",
    "\n",
    "                id_iou_frame_json_name = str(init_id).zfill(3) + '_' + ('%.2f'%iou).replace('.', '') + '_' +  frame_name + '.json'\n",
    "\n",
    "                json_path = os.path.join(frame_experiment_task_dir, id_iou_frame_json_name)\n",
    "\n",
    "\n",
    "                with open(json_path, 'w') as f:\n",
    "                    json.dump(task_info, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/sdb1/home/kbotashev/iros_paper/ibr_dataset/scenes/playroom/playroom_task/sparse/0/images.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/sdb1/home/kbotashev/mip-nerf_projects/gaussian_splatting_original/gaussian-splatting/scene/dataset_readers.py:156\u001b[0m, in \u001b[0;36mreadColmapSceneInfo\u001b[0;34m(path, images, eval, llffhold, cameras_extrinsic_file_custom)\u001b[0m\n\u001b[1;32m    155\u001b[0m cameras_intrinsic_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse/0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcameras.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m cam_extrinsics \u001b[38;5;241m=\u001b[39m \u001b[43mread_extrinsics_binary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcameras_extrinsic_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m cam_intrinsics \u001b[38;5;241m=\u001b[39m read_intrinsics_binary(cameras_intrinsic_file)\n",
      "File \u001b[0;32m/mnt/sdb1/home/kbotashev/mip-nerf_projects/gaussian_splatting_original/gaussian-splatting/scene/colmap_loader.py:187\u001b[0m, in \u001b[0;36mread_extrinsics_binary\u001b[0;34m(path_to_model_file)\u001b[0m\n\u001b[1;32m    186\u001b[0m images \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_to_model_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    188\u001b[0m     num_reg_images \u001b[38;5;241m=\u001b[39m read_next_bytes(fid, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/sdb1/home/kbotashev/iros_paper/ibr_dataset/scenes/playroom/playroom_task/sparse/0/images.bin'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m task_dir_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ply_path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_base/sparse/0/points3D.ply\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_task\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m base_dir_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ply_path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_base/sparse/0/points3D.ply\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_base\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 7\u001b[0m scene_info_task \u001b[38;5;241m=\u001b[39m \u001b[43mreadColmapSceneInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_dir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m scene_info_base \u001b[38;5;241m=\u001b[39m readColmapSceneInfo(base_dir_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28meval\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m pcd_o3d \u001b[38;5;241m=\u001b[39m o3d\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_point_cloud(ply_path)\n",
      "File \u001b[0;32m/mnt/sdb1/home/kbotashev/mip-nerf_projects/gaussian_splatting_original/gaussian-splatting/scene/dataset_readers.py:161\u001b[0m, in \u001b[0;36mreadColmapSceneInfo\u001b[0;34m(path, images, eval, llffhold, cameras_extrinsic_file_custom)\u001b[0m\n\u001b[1;32m    159\u001b[0m         cameras_extrinsic_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse/0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    160\u001b[0m         cameras_intrinsic_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse/0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcameras.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 161\u001b[0m         cam_extrinsics \u001b[38;5;241m=\u001b[39m \u001b[43mread_extrinsics_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcameras_extrinsic_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m         cam_intrinsics \u001b[38;5;241m=\u001b[39m read_intrinsics_text(cameras_intrinsic_file)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/sdb1/home/kbotashev/mip-nerf_projects/gaussian_splatting_original/gaussian-splatting/scene/colmap_loader.py:249\u001b[0m, in \u001b[0;36mread_extrinsics_text\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03mTaken from https://github.com/colmap/colmap/blob/dev/scripts/python/read_write_model.py\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m images \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m         line \u001b[38;5;241m=\u001b[39m fid\u001b[38;5;241m.\u001b[39mreadline()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/sdb1/home/kbotashev/iros_paper/ibr_dataset/scenes/playroom/playroom_task/sparse/0/images.txt'"
     ]
    }
   ],
   "source": [
    "room_name = 'apartment_1'\n",
    "ply_path_base = \"/mnt/sdb1/home/kbotashev/iros_paper/replica_dataset_1/scenes/$roomname$/$roomname$_base/sparse/0/points3D.ply\"\n",
    "ply_path = ply_path_base.replace('$roomname$', room_name)\n",
    "task_dir_path = os.path.join(ply_path.replace('_base/sparse/0/points3D.ply', '_task'))\n",
    "base_dir_path = os.path.join(ply_path.replace('_base/sparse/0/points3D.ply', '_base'))\n",
    "\n",
    "scene_info_task = readColmapSceneInfo(task_dir_path, 'images', eval=False)\n",
    "scene_info_base = readColmapSceneInfo(base_dir_path, 'images', eval=False)\n",
    "\n",
    "pcd_o3d = o3d.io.read_point_cloud(ply_path)\n",
    "pcd_o3d = pcd_o3d.voxel_down_sample(voxel_size=0.025)\n",
    "points_tensor = torch.tensor(np.asarray(pcd_o3d.points)).unsqueeze(0).cuda().float()\n",
    "colors_tensor = torch.tensor(np.asarray(pcd_o3d.colors)).unsqueeze(0).cuda().float()\n",
    "points = Pointclouds(points_tensor, features=colors_tensor)\n",
    "\n",
    "args = namedtuple('args', ['resolution', 'data_device'])\n",
    "args = args(2, 'cuda:1')\n",
    "pipe = namedtuple('pipe', ['convert_SHs_python', 'compute_cov3D_python', 'debug'])\n",
    "pipe = pipe(False, False, False)\n",
    "bg_color = [0, 0, 0]\n",
    "background = torch.tensor(bg_color, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "ids = np.arange(len(scene_info_task.train_cameras))\n",
    "\n",
    "data_sparse_room = data_sparse[data_sparse['room_name'] == room_name]\n",
    "\n",
    "for id in tqdm(ids):\n",
    "    cam_info = scene_info_task.train_cameras[id]\n",
    "    camera = loadCam(args=args, id = id, cam_info=cam_info, resolution_scale=1)\n",
    "\n",
    "    height = camera.image_height\n",
    "    width = camera.image_width\n",
    "    fx = camera.fx\n",
    "    fy = camera.fy\n",
    "    cx = camera.cx\n",
    "    cy = camera.cy\n",
    "    scene_results = {}\n",
    "    scene_results['point_cloud_path'] = ply_path\n",
    "    scene_results['scene'] = ply_path.split('/')[-5]\n",
    "    scene_results['img_name'] = cam_info.image_name\n",
    "    frame_results = {0:{}}\n",
    "\n",
    "    T_gt = mrob.geometry.SE3(mrob.geometry.SO3(camera.R), camera.T)\n",
    "    set_gt, _ = compute_point_cloud_camera_fraction(**{'R':T_gt.R(), 'tvec':T_gt.t(), \n",
    "                            \"fx\":fx, 'fy':fy, \n",
    "                            'cx':cy, 'cy':cy, \n",
    "                            'height':height, 'width':width, \n",
    "                            'points':points})\n",
    "    \n",
    "    row = data_sparse_room[data_sparse_room['frame_id'] == id]\n",
    "\n",
    "    top5_frames = row['top_k_refs'].item().replace('[', '').replace('\\n', '').replace(']', '').replace(\"'\", '').split(' ')[:5]\n",
    "\n",
    "\n",
    "    init_ids = [int(topk_path.split('/')[-1].split('.png')[0]) for topk_path in top5_frames]\n",
    "\n",
    "    for init_id in init_ids:\n",
    "\n",
    "        camera_init = loadCam(args=args, id = init_id, cam_info=scene_info_base.train_cameras[init_id], resolution_scale=1)\n",
    "\n",
    "        set_init, image_init = compute_point_cloud_camera_fraction(**{'R':camera_init.R, 'tvec':camera_init.T, \n",
    "                        \"fx\":fx, 'fy':fy, \n",
    "                        'cx':cy, 'cy':cy, \n",
    "                        'height':height, 'width':width, \n",
    "                        'points':points,\n",
    "                        'build_image':True})\n",
    "        \n",
    "        norm_image = cv2.normalize(image_init[0].cpu().numpy(), None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "\n",
    "        norm_image = norm_image.astype(np.uint8)\n",
    "\n",
    "        iou, intersection_indices, union_indices = compute_iou_2sets(set_gt, set_init)\n",
    "\n",
    "        frame_results[0][init_id] = {'R_init':camera_init.R,\n",
    "                                'T_init':camera_init.T,\n",
    "                                'iou':iou,\n",
    "                                'init_fraction_set_idx':list(set_init),\n",
    "                                'intersection_idx':intersection_indices,\n",
    "                                'union_idx':union_indices,\n",
    "                                'init_image':norm_image,\n",
    "                                'init_base_id':init_id,\n",
    "                                'black_pixels_ratio':0\n",
    "                                                        }\n",
    "                \n",
    "        # init_frames_stats = {key:len(frame_results[key]) for key in frame_results.keys()}    \n",
    "    \n",
    "    scene_results['frames'] = {'img_path':cam_info.image_path,\n",
    "                                'R':cam_info.R,\n",
    "                                'T':cam_info.T,\n",
    "                                'uid':id,\n",
    "                                'FovY':cam_info.FovY,\n",
    "                                'FovX':cam_info.FovX,\n",
    "                                'image':np.array(cam_info.image),\n",
    "                                'width':cam_info.width,\n",
    "                                'height':cam_info.height,\n",
    "                                'qvec':cam_info.qvec,\n",
    "                                'cx':cam_info.cx,\n",
    "                                'cy':cam_info.cy,\n",
    "                                'gt_fraction_set_idx':list(set_gt),\n",
    "                                'init_frames_iou_bins':frame_results,\n",
    "                                # 'init_frames_iou_bins_stats':init_frames_stats\n",
    "                                }\n",
    "    \n",
    "    os.makedirs(os.path.join(task_dir_path, 'task-base_images_pairs'), exist_ok = True)\n",
    "    with open(os.path.join(task_dir_path, 'task-base_images_pairs', cam_info.image_name + '.pickle'), 'wb') as handle:\n",
    "        pickle.dump(scene_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print('---FINISHED---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 35.10it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 49.75it/s]\n"
     ]
    }
   ],
   "source": [
    "tasks_root = '/mnt/sdb1/home/kbotashev/iros_paper/replica_dataset_1/results_task_rebase_vladnet/tasks'\n",
    "\n",
    "for room in ['apartment_1', 'office_2']:\n",
    "    for camera_type in ['lietorch']:\n",
    "    # for camera_type in ['lietorch', 'qtvec']:\n",
    "        room_task_info = {  \n",
    "                            'room_name':room,\n",
    "                            # 'camera_type':camera_type,\n",
    "                            # # 'camera_type':'qtvec',\n",
    "                            # 'solving_method':'vanilla',\n",
    "                            # 'solving_method_args': None,\n",
    "                            # 'loss_type':'l1',\n",
    "                            # 'optimizer_type':'adam',\n",
    "                            # 'init_render_resolution':2,\n",
    "                            # 'iterations':2000,\n",
    "                            # 'exit_psnr_parameter':1e-4,\n",
    "                            # 'pose_lr_init':0.01,\n",
    "                            # 'pose_lr_final':1e-5,\n",
    "                            # 'pose_lr_delay_steps':0,\n",
    "                            # 'pose_lr_delay_mult':0,\n",
    "                            'start_frame':0,\n",
    "                            'last_frame':32,\n",
    "                            'experiments_base_dir':'/mnt/sdb1/home/kbotashev/iros_paper/replica_dataset_1/'\n",
    "                        }\n",
    "\n",
    "        ply_path = os.path.join(room_task_info['experiments_base_dir'], \n",
    "                                'output', room_task_info['room_name'], \n",
    "                                'point_cloud/iteration_40000/point_cloud.ply')\n",
    "\n",
    "        frames_info_pickle_paths = sorted(glob(os.path.join(room_task_info['experiments_base_dir'], \n",
    "                                        'scenes', room_task_info['room_name'], \n",
    "                                        room_task_info['room_name']+'_task', 'task-rebase_images_pairs/*.pickle')))\n",
    "\n",
    "        for frames_info_pickle_path in tqdm(frames_info_pickle_paths[room_task_info['start_frame']:room_task_info['last_frame']]):\n",
    "            frame_name = frames_info_pickle_path.split('/')[-1].split('.pickle')[0]\n",
    "\n",
    "            with open(frames_info_pickle_path, 'rb') as handle:\n",
    "                frame_info = pickle.load(handle)\n",
    "\n",
    "            for init_id in frame_info['frames']['init_frames_iou_bins'][0].keys():\n",
    "                task_info = copy.copy(room_task_info)\n",
    "                del task_info['start_frame']\n",
    "                del task_info['last_frame']\n",
    "\n",
    "                pickle_path = os.path.join(room_task_info['experiments_base_dir'], \n",
    "                                    'scenes', room_task_info['room_name'], \n",
    "                                    room_task_info['room_name']+'_task',\n",
    "                                    'task-rebase_images_pairs',  frame_name + '.pickle')\n",
    "                \n",
    "                task_info['ply_path'] = ply_path\n",
    "                task_info['pickle_path'] = pickle_path\n",
    "                task_info['init_id'] = init_id\n",
    "                task_info['iou_bin'] = 0\n",
    "                task_info['frame_name'] = frame_name\n",
    "\n",
    "                room_task_dir = os.path.join(tasks_root, task_info['room_name'])\n",
    "\n",
    "                iou = frame_info['frames']['init_frames_iou_bins'][0][init_id]['iou']\n",
    "\n",
    "                frame_experiment_task_dir = os.path.join(room_task_dir, frame_name, ('%.2f'%0).replace('.', ''))\n",
    "\n",
    "                os.makedirs(frame_experiment_task_dir, exist_ok=True)\n",
    "\n",
    "                id_iou_frame_json_name = str(init_id).zfill(3) + '_' + ('%.2f'%iou).replace('.', '') + '_' +  frame_name + '.json'\n",
    "\n",
    "                json_path = os.path.join(frame_experiment_task_dir, id_iou_frame_json_name)\n",
    "\n",
    "\n",
    "                with open(json_path, 'w') as f:\n",
    "                    json.dump(task_info, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_frame = 1\n",
    "room_names = ['office_2', 'apartment_1']\n",
    "frame_num = np.arange(32)\n",
    "camera_types = ['lietorch']\n",
    "solving_methods = ['coarse']\n",
    "init_render_resolutions = [2]\n",
    "\n",
    "# step_frame = 1\n",
    "# room_names = ['apartment_0', 'office_0', 'office_2', 'apartment_1', 'office_4']\n",
    "# frame_num = np.arange(32)\n",
    "# camera_types = ['qtvec', 'lietorch']\n",
    "# solving_methods = ['vanilla', 'coarse']\n",
    "\n",
    "# loss_types=['l1']\n",
    "# optimizer_types=['adam']\n",
    "# init_render_resolutions=[2]\n",
    "# iterations_params=[2000]\n",
    "# exit_psnr_parameters=[5e-5],\n",
    "# pose_lrs_init=[0.01]\n",
    "# pose_lrs_final=[1e-5]\n",
    "# pose_lrs_delay_steps=[0]\n",
    "# pose_lrs_delay_mult=[0]\n",
    "\n",
    "# solving_methods_args = [{ \n",
    "#                         'max_scale':2,\n",
    "#                         'num_tries':5,\n",
    "#                         'blur_2d_c2f_kernel_size':201,\n",
    "#                         'blur_2d_c2f_schedule':[0.05, 0.025, 0.0125, 0.00625, 0.00625, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "#                        }]\n",
    "\n",
    "step_frame = 1\n",
    "room_names = ['drjohnson', 'playroom']\n",
    "frame_num = np.arange(32)\n",
    "camera_types = ['lietorch']\n",
    "solving_methods = ['coarse']\n",
    "init_render_resolutions = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "for start_frame in frame_num:\n",
    "    for camera_type in camera_types:\n",
    "            for room_name in room_names:\n",
    "                for solving_method in solving_methods:\n",
    "                    for init_render_resolution in init_render_resolutions:\n",
    "                        combinations.append([room_name, start_frame, start_frame+1, camera_type, solving_method, init_render_resolution])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinations += combinations[-16:]\n",
    "combinations = np.array(combinations).reshape(8,1, 8, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_bash_dir = '/mnt/sdb1/home/kbotashev/iros_paper/ibr_dataset/results/input_bashs'\n",
    "min_gpu = 0\n",
    "terminal_lines = []\n",
    "for gpu_id, combo6 in enumerate(combinations):\n",
    "    for gpu_sub_id, combo3 in enumerate(combo6):\n",
    "        lines = []\n",
    "        for combo in combo3:\n",
    "            lines.append('\\nCUDA_VISIBLE_DEVICES='+str(gpu_id+min_gpu) + \n",
    "                  ', /mnt/sdb1/home/kbotashev/anaconda3/envs/gs102/bin/python' + \n",
    "                  ' /mnt/sdb1/home/kbotashev/mip-nerf_projects/gaussian_splatting_original/gaussian-splatting/solve_pose_estimation.py ' + \\\n",
    "                    '--room_name='+combo[0] + ' --start_frame='+combo[1] + ' --end_frame='+combo[2] + \\\n",
    "                    ' --camera_type='+combo[3] + ' --solving_method='+combo[4] + ' --init_render_resolution='+combo[5])\n",
    "        f = open(os.path.join(output_bash_dir, str(gpu_id+min_gpu) + '_' + str(gpu_sub_id) + \".sh\"), \"w\")\n",
    "        f.writelines(lines)\n",
    "        f.close()\n",
    "        terminal_lines.append('\\nnohup bash ' + os.path.join(output_bash_dir, str(gpu_id+min_gpu) + \n",
    "                                                           '_' + str(gpu_sub_id) + \".sh\") + ' > ' + \n",
    "                                                           os.path.join(output_bash_dir, str(gpu_id+min_gpu) + '_' + str(gpu_sub_id) + '_log.out &'))\n",
    "\n",
    "f = open(os.path.join(output_bash_dir, \"run_bashes.sh\"), \"w\")\n",
    "f.writelines(terminal_lines)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "output_bash_dir = '/mnt/sdb1/home/kbotashev/iros_paper/replica_dataset_1/results_task_rebase_vladnet/input_bashs'\n",
    "min_gpu = 0\n",
    "terminal_lines = []\n",
    "for gpu_id, combo6 in enumerate(combinations):\n",
    "    for gpu_sub_id, combo3 in enumerate(combo6):\n",
    "        lines = []\n",
    "        for combo in combo3:\n",
    "            lines.append('\\nCUDA_VISIBLE_DEVICES='+str(gpu_id+min_gpu) + \n",
    "                  ', /mnt/sdb1/home/kbotashev/anaconda3/envs/gs102/bin/python' + \n",
    "                  ' /mnt/sdb1/home/kbotashev/mip-nerf_projects/gaussian_splatting_original/gaussian-splatting/solve_pose_estimation.py ' + \\\n",
    "                    '--room_name='+combo[0] + ' --start_frame='+combo[1] + ' --end_frame='+combo[2] + \\\n",
    "                    ' --camera_type='+combo[3] + ' --solving_method='+combo[4] + ' --init_render_resolution='+combo[5])\n",
    "        f = open(os.path.join(output_bash_dir, str(gpu_id+min_gpu) + '_' + str(gpu_sub_id) + \".sh\"), \"w\")\n",
    "        f.writelines(lines)\n",
    "        f.close()\n",
    "        terminal_lines.append('\\nnohup bash ' + os.path.join(output_bash_dir, str(gpu_id+min_gpu) + \n",
    "                                                           '_' + str(gpu_sub_id) + \".sh\") + ' > ' + \n",
    "                                                           os.path.join(output_bash_dir, str(gpu_id+min_gpu) + '_' + str(gpu_sub_id) + '_log.out &'))\n",
    "\n",
    "f = open(os.path.join(output_bash_dir, \"run_bashes.sh\"), \"w\")\n",
    "f.writelines(terminal_lines)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs102",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

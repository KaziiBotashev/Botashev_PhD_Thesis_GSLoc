{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "from os import makedirs\n",
    "from gaussian_renderer import render_lie, render_qtvec\n",
    "import torchvision\n",
    "from utils.general_utils import safe_state\n",
    "from argparse import ArgumentParser\n",
    "from arguments import ModelParams, PipelineParams, get_combined_args, pose_estimation_params\n",
    "from gaussian_renderer import GaussianModel\n",
    "from utils.image_utils import psnr\n",
    "from utils.loss_utils import EdgeDetection\n",
    "import numpy as np\n",
    "from utils.loss_utils import l1_loss, ssim, l2_loss\n",
    "from copy import deepcopy\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity as LPIPS\n",
    "import pypose as pp\n",
    "\n",
    "from scene.dataset_readers import readColmapSceneInfo\n",
    "from utils.camera_utils import loadCam\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import math\n",
    "from diff_gaussian_rasterization_lie_pp import GaussianRasterizationSettings, GaussianRasterizer\n",
    "from scene.gaussian_model import GaussianModel\n",
    "from utils.sh_utils import eval_sh\n",
    "\n",
    "import pickle\n",
    "\n",
    "from scene.dataset_readers import CameraInfo\n",
    "from PIL import Image\n",
    "import mrob\n",
    "import open3d as o3d\n",
    "\n",
    "from arguments import  pose_estimation_params\n",
    "from utils.general_utils import get_expon_lr_func\n",
    "import cv2\n",
    "from glob import glob\n",
    "import copy\n",
    "import json\n",
    "\n",
    "import kernels\n",
    "import torch.nn.functional as torch_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_schedule(x, schedule, left=0, right=1):\n",
    "    # linear interprete between a list of schedule values\n",
    "    assert left <= x and right >= x\n",
    "    if isinstance(schedule, torch.Tensor):\n",
    "        schedule = schedule.cpu().detach().numpy()\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        x = x.cpu().detach().numpy()\n",
    "    xs = np.linspace(left, right, len(schedule))\n",
    "    return np.interp(x, xs, schedule)\n",
    "\n",
    "def get_number_of_max_iou_iters(num, max_iters=64):\n",
    "    return num if num < max_iters else max_iters\n",
    "\n",
    "def get_render_func(camera_type):\n",
    "    if camera_type == 'qtvec':\n",
    "        render = render_qtvec\n",
    "    elif camera_type == 'lietorch':\n",
    "        render = render_lie\n",
    "    return render\n",
    "\n",
    "def get_loss_func(loss_type):\n",
    "    if loss_type == 'l1':\n",
    "        loss_func = l1_loss\n",
    "    elif loss_type == 'l2':\n",
    "        loss_func = l2_loss\n",
    "    return loss_func\n",
    "\n",
    "def get_optimizer_func(optimizer_type):\n",
    "    if optimizer_type == 'adam':\n",
    "        optimizer_func = torch.optim.Adam\n",
    "    return optimizer_func\n",
    "\n",
    "def image_torch_to_np(image_init):\n",
    "    norm_image = cv2.normalize(image_init.squeeze().detach().cpu().numpy().transpose(1,2,0), None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    norm_image = norm_image.astype(np.uint8)\n",
    "    return norm_image\n",
    "\n",
    "class Solver:\n",
    "    def __init__(self, camera, optimizer_func, camera_pose_estimation_params):\n",
    "        \n",
    "        self.pose_optimizer = optimizer_func([{'params': camera.world_view_transform_, \n",
    "                                                 'lr': camera_pose_estimation_params.pose_lr_init, \"name\": \"pose\"}], \n",
    "                                               lr = camera_pose_estimation_params.pose_lr_init)\n",
    "        self.pose_scheduler_args = get_expon_lr_func(lr_init=camera_pose_estimation_params.pose_lr_init,\n",
    "                            lr_final=camera_pose_estimation_params.pose_lr_final,\n",
    "                            lr_delay_steps=camera_pose_estimation_params.pose_lr_delay_steps, \n",
    "                            lr_delay_mult=camera_pose_estimation_params.pose_lr_delay_mult,\n",
    "                            max_steps=camera_pose_estimation_params.pose_lr_max_steps)\n",
    "        \n",
    "    def update_learning_rate_pose(self, iteration, factor = 1):\n",
    "        ''' Learning rate scheduling per step '''\n",
    "        for param_group in self.pose_optimizer.param_groups:\n",
    "            if param_group[\"name\"] == \"pose\":\n",
    "                if type(self.pose_scheduler_args) == list:\n",
    "                    lr = self.pose_scheduler_args[iteration] * factor\n",
    "                else:\n",
    "                    lr = self.pose_scheduler_args(iteration) * factor\n",
    "                param_group['lr'] = lr\n",
    "                return lr\n",
    "            \n",
    "\n",
    "def blur_image(gt_image, iteration, iterations, max_scale, blur_2d_c2f_kernel_size, blur_2d_c2f_schedule):\n",
    "    H = gt_image.shape[1]\n",
    "    W = gt_image.shape[2]\n",
    "    c2f_alternate_2D_mode = False\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    # blur_2d_c2f_schedule = [0.05, 0.025, 0.0125, 0.00625, 0.00625, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    # blur_2d_c2f_schedule = [0.025, 0.0125, 0.00625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    # blur_2d_c2f_kernel_size = 201\n",
    "    # max_scale = 1\n",
    "\n",
    "    if c2f_alternate_2D_mode == \"sample\":\n",
    "        scales = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "    else:\n",
    "        scales = [0.0, max_scale]\n",
    "    # get kernels\n",
    "    kernels_dict = dict() # dictionary from scale to kernel\n",
    "    for sc in scales:\n",
    "        blur_param = interp_schedule(float(iteration/iterations), blur_2d_c2f_schedule)\n",
    "        blur_param = torch.tensor(blur_param, device=device)\n",
    "        blur_param *= sc\n",
    "        # get kernel\n",
    "\n",
    "        kernel_width = blur_param * (W + H)/2\n",
    "        kernel_1d = kernels.get_gaussian_kernel(kernel_width, blur_2d_c2f_kernel_size)\n",
    "\n",
    "        kernel_1d = kernel_1d.to(device=device,dtype=torch.float32)\n",
    "\n",
    "        kernel_1d = kernel_1d.expand(1,1,-1)\n",
    "\n",
    "        kernels_dict[sc] = (kernel_1d, kernel_width)\n",
    "\n",
    "    # generte blurred GT images\n",
    "    blurred_gt_cached_images = dict()\n",
    "\n",
    "    for sc, k in kernels_dict.items():\n",
    "        kernel_1d, kernel_width = k\n",
    "        # skip kernel if kernel_width too small\n",
    "        if kernel_width < 0.01:\n",
    "            images = gt_image\n",
    "        else:\n",
    "            # perform 2D seperated convolution\n",
    "            images = gt_image\n",
    "            kernel_size = kernel_1d.shape[-1]\n",
    "            pad_size= (kernel_size //2, kernel_size //2)\n",
    "            images = torch_F.pad(images, pad_size, mode=\"replicate\")\n",
    "            images = torch_F.conv1d(images, kernel_1d.expand(H,1,-1), bias=None, stride=1, padding=0, dilation=1, groups=H)\n",
    "            images = images.permute(0,2,1)\n",
    "            images = torch_F.pad(images, pad_size, mode=\"replicate\")\n",
    "            images = torch_F.conv1d(images, kernel_1d.expand(W,1,-1), bias=None, stride=1, padding=0, dilation=1, groups=W)\n",
    "            images = images.permute(0,2,1).reshape(1, 3, H, W).contiguous()\n",
    "        blurred_gt_cached_images[sc] = images\n",
    "    return blurred_gt_cached_images\n",
    "\n",
    "\n",
    "def solve_coarse(cam_info_init, task_info, gaussians, solving_args = None):\n",
    "    args = namedtuple('args', ['resolution', 'data_device'])\n",
    "    args = args(task_info['init_render_resolution'], 'cuda')\n",
    "    pipe = namedtuple('pipe', ['convert_SHs_python', 'compute_cov3D_python', 'debug'])\n",
    "    pipe = pipe(False, False, False)\n",
    "    bg_color = [0, 0, 0]\n",
    "    background = torch.tensor(bg_color, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "    camera_type = task_info['camera_type']\n",
    "    loss_type = task_info['loss_type']\n",
    "    optimizer_type = task_info['optimizer_type']\n",
    "\n",
    "    iterations = task_info['iterations']\n",
    "    exit_psnr_parameter = task_info['exit_psnr_parameter']\n",
    "\n",
    "    pose_lr_init = task_info['pose_lr_init']\n",
    "    pose_lr_final = task_info['pose_lr_final']\n",
    "    pose_lr_delay_steps = task_info['pose_lr_delay_steps']\n",
    "    pose_lr_delay_mult = task_info['pose_lr_delay_mult']\n",
    "\n",
    "    render_func = get_render_func(camera_type)\n",
    "    loss_func = get_loss_func(loss_type)\n",
    "    optimizer_func = get_optimizer_func(optimizer_type)\n",
    "\n",
    "    # camera_gt = loadCam(args=args, id = 0, cam_info=cam_info_gt, resolution_scale=1, camera_type=camera_type)\n",
    "    camera_init = loadCam(args=args, id = 0, cam_info=cam_info_init, resolution_scale=1, camera_type=camera_type)\n",
    "\n",
    "    pose_solver = Solver(camera_init, optimizer_func, pose_estimation_params(pose_lr_init, pose_lr_final, pose_lr_delay_steps,\n",
    "                                                        pose_lr_delay_mult, iterations, False))\n",
    "    \n",
    "    num_tries = solving_args['num_tries']\n",
    "    max_scale_ = solving_args['max_scale']\n",
    "    blur_2d_c2f_kernel_size = solving_args['blur_2d_c2f_kernel_size']\n",
    "    blur_2d_c2f_schedule = solving_args['blur_2d_c2f_schedule']\n",
    "    \n",
    "    current_try = 0\n",
    "    success = 0\n",
    "\n",
    "    while current_try < num_tries and success == 0:\n",
    "        # if current_try > 1:\n",
    "        #     max_scale += 1\n",
    "        prev_psnr = 1000\n",
    "        max_psnr = -1\n",
    "        init_psnr = 0\n",
    "\n",
    "        lpips = LPIPS(normalize=True).cuda()\n",
    "        init_qtvec = camera_init.world_view_transform_\n",
    "        if current_try == 0:\n",
    "            rendering_init = torch.clamp(render_func(camera_init, gaussians, pipe, background)[\"render\"], 0, 1)\n",
    "        gt_image = camera_init.original_image.cuda()\n",
    "\n",
    "        progress_bar = tqdm(range(0, iterations), desc=\"Optimizing camera \")\n",
    "        if camera_type == 'lietorch':\n",
    "            best_viewpoint_cam = torch.nn.Parameter(camera_init.world_view_transform_[0].data.detach().requires_grad_())\n",
    "        else:\n",
    "            best_viewpoint_cam = camera_init.world_view_transform_\n",
    "        converged = False\n",
    "        counter = 0\n",
    "        \n",
    "        for iteration in range(0, iterations):        \n",
    "            image = render_func(camera_init, gaussians, pipe, background)[\"render\"]\n",
    "            image = torch.clamp(image, 0, 1)\n",
    "            max_scale = np.random.rand()*max_scale_\n",
    "            gt_image_blur_dict = blur_image(gt_image, iteration, \n",
    "                                            iterations, max_scale=max_scale, \n",
    "                                            blur_2d_c2f_kernel_size = blur_2d_c2f_kernel_size,\n",
    "                                            blur_2d_c2f_schedule = blur_2d_c2f_schedule)\n",
    "            image_blur_dict = blur_image(image, iteration, \n",
    "                                         iterations, max_scale=max_scale, \n",
    "                                        blur_2d_c2f_kernel_size = blur_2d_c2f_kernel_size,\n",
    "                                        blur_2d_c2f_schedule = blur_2d_c2f_schedule)\n",
    "\n",
    "            L1 = loss_func(image_blur_dict[max_scale], gt_image_blur_dict[max_scale])\n",
    "            loss_value = L1\n",
    "            psnr_value = psnr(image, gt_image).mean().item()\n",
    "            loss_value.backward()\n",
    "\n",
    "            if iteration == 0 and current_try == 0:\n",
    "                loss_init = loss_value.item()\n",
    "\n",
    "            if psnr_value >= max_psnr:\n",
    "                max_psnr = psnr_value \n",
    "                if camera_type == 'lietorch':\n",
    "                    best_viewpoint_cam = torch.nn.Parameter(camera_init.world_view_transform_[0].data.detach().requires_grad_())\n",
    "                else:\n",
    "                    best_viewpoint_cam = camera_init.world_view_transform_\n",
    "\n",
    "            if abs(psnr_value - prev_psnr) <= exit_psnr_parameter:\n",
    "                counter += 1\n",
    "                if counter == 3:\n",
    "                    converged = True\n",
    "                    print('Converged. PSNR optimized as: ' \\\n",
    "                    + format(init_psnr, '.7f') + ' -> ' + format(max_psnr, '.7f'))\n",
    "                    counter = 0\n",
    "                    progress_bar.close()\n",
    "                    break\n",
    "            \n",
    "            progress_bar.set_postfix({\"Loss\": f\"{loss_value.item():.{7}f}\", 'PSNR' : f\"{psnr_value:.{7}f}\", 'max_scale' : f\"{max_scale:.{4}f}\"})\n",
    "            progress_bar.update()\n",
    "            prev_psnr = psnr_value\n",
    "            \n",
    "            init_psnr = psnr_value if iteration == 0 else init_psnr\n",
    "\n",
    "            with torch.no_grad():\n",
    "                if camera_type == 'lietorch':\n",
    "                    camera_init.world_view_transform_.grad = camera_init.world_view_transform.grad[:-1].unsqueeze(0)\n",
    "                pose_solver.update_learning_rate_pose(iteration)\n",
    "                pose_solver.pose_optimizer.step()\n",
    "                pose_solver.pose_optimizer.zero_grad(set_to_none = True)\n",
    "                if camera_type == 'lietorch':\n",
    "                    camera_init.world_view_transform = torch.nn.Parameter(camera_init.world_view_transform_[0].data.detach().requires_grad_())\n",
    "        progress_bar.close()\n",
    "\n",
    "        if camera_type == 'lietorch':\n",
    "            camera_init.world_view_transform  = best_viewpoint_cam\n",
    "        else:\n",
    "            camera_init.world_view_transform_ = best_viewpoint_cam \n",
    "\n",
    "        rendering_result = torch.clamp(render_func(camera_init, gaussians, pipe, background)['render'], 0, 1)\n",
    "        result_psnr = psnr(rendering_result, gt_image).mean().item()\n",
    "        result_ssim = ssim(rendering_result, gt_image).mean().item()\n",
    "        result_lpips = lpips(rendering_result.unsqueeze(0), gt_image.unsqueeze(0)).mean().item()\n",
    "\n",
    "        if current_try == 0:\n",
    "            init_psnr = psnr(rendering_init, gt_image).mean().item()\n",
    "            init_ssim = ssim(rendering_init, gt_image).mean().item()\n",
    "            init_lpips = lpips(rendering_init.unsqueeze(0), gt_image.unsqueeze(0)).mean().item()\n",
    "\n",
    "        success = 1 if result_psnr > 27 else 0\n",
    "        current_try += 1\n",
    "    \n",
    "\n",
    "    return {'qtvec_init':init_qtvec.detach().cpu().numpy(),\n",
    "            'psnr_init':init_psnr,\n",
    "            'ssim_init':init_ssim,\n",
    "            'lpips_init':init_lpips,\n",
    "            'loss_init':loss_init,\n",
    "            'image_init':image_torch_to_np(rendering_init),\n",
    "            'image_gt':image_torch_to_np(gt_image),\n",
    "\n",
    "            'qtvec_result':best_viewpoint_cam.detach().cpu().numpy(),\n",
    "            'psnr_result':result_psnr,\n",
    "            'ssim_result':result_ssim,\n",
    "            'lpips_result':result_lpips,\n",
    "            'loss_result':loss_value.item(),\n",
    "            'image_result':image_torch_to_np(rendering_result),\n",
    "            'iterations_to_result':iteration,\n",
    "            'converged':converged,\n",
    "            'success':success,\n",
    "            }\n",
    "\n",
    "\n",
    "def get_solving_func(solving_method):\n",
    "    if solving_method == 'vanilla':\n",
    "        solving_func = solve_vanilla\n",
    "    if solving_method == 'coarse':\n",
    "        solving_func = solve_coarse\n",
    "    return solving_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_name = pickle_path_orig.split('/')[-4]\n",
    "frame_id = int(pickle_path_orig.split('/')[-3])\n",
    "iou_bin = float('0.' + pickle_path_orig.split('/')[-2][1:])\n",
    "index = int(pickle_path_orig.split('/')[-1].split('_')[0])\n",
    "\n",
    "solving_method_args = { \n",
    "                        'max_scale':2,\n",
    "                        'num_tries':5,\n",
    "                        'blur_2d_c2f_kernel_size':201,\n",
    "                        'blur_2d_c2f_schedule':[0.05, 0.025, 0.0125, 0.00625, 0.00625, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_info = {  \n",
    "                        'room_name':room_name,\n",
    "                        'camera_type':'lietorch',\n",
    "                        # 'camera_type':'qtvec',\n",
    "                        'solving_method':'coarse',\n",
    "                        # 'solving_method':'vanilla',\n",
    "                        'solving_method_args': solving_method_args,\n",
    "                        'loss_type':'l1',\n",
    "                        'optimizer_type':'adam',\n",
    "                        'init_render_resolution':2,\n",
    "                        'iterations':2000,\n",
    "                        'exit_psnr_parameter':1e-5,\n",
    "                        'pose_lr_init':0.01,\n",
    "                        'pose_lr_final':1e-5,\n",
    "                        'pose_lr_delay_steps':0,\n",
    "                        'pose_lr_delay_mult':0, \n",
    "                        'start_frame':0,\n",
    "                        'last_frame':32,\n",
    "                        'experiments_base_dir':'/mnt/sdb1/home/kbotashev/iros_paper/replica_dataset_1/'\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_name = task_info['room_name']\n",
    "\n",
    "experiments_base_dir = task_info['experiments_base_dir']\n",
    "\n",
    "ply_path = os.path.join(experiments_base_dir, \n",
    "                        'output', room_name, \n",
    "                        'point_cloud/iteration_40000/point_cloud.ply')\n",
    "\n",
    "gaussians = GaussianModel(sh_degree=3)\n",
    "gaussians.load_ply(ply_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_id = 28\n",
    "# iou_bin = 0.30\n",
    "# index = 31\n",
    "\n",
    "pickle_path = os.path.join(experiments_base_dir, 'scenes', room_name, room_name + '_task', 'images_pairs_light', str(frame_id).zfill(5) + '.pickle')\n",
    "with open(pickle_path, 'rb') as handle:\n",
    "    frames_info = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solving_method = task_info['solving_method']\n",
    "solving_args = task_info['solving_method_args']\n",
    "solve_func = get_solving_func(solving_method=solving_method)\n",
    "\n",
    "\n",
    "FovY = frames_info['frames']['FovY']\n",
    "FovX = frames_info['frames']['FovX']\n",
    "width = frames_info['frames']['width']\n",
    "height = frames_info['frames']['height']\n",
    "cx = frames_info['frames']['cx']\n",
    "cy = frames_info['frames']['cy']\n",
    "\n",
    "image_gt = Image.fromarray(frames_info['frames']['image'])\n",
    "image_path = frames_info['frames']['img_path']\n",
    "image_name = frames_info['img_name']\n",
    "R_gt = frames_info['frames']['R']\n",
    "t_gt = frames_info['frames']['T']\n",
    "\n",
    "# cam_info_gt = CameraInfo(uid=0, R=R_gt, T=t_gt, FovY=FovY, FovX=FovX, image=image_gt,\n",
    "#                          image_path=image_path, image_name=image_name, width=width,\n",
    "#                          height=height, qvec = None, cx = cx, cy = cy)\n",
    "\n",
    "image_init = frames_info['frames']['init_frames_iou_bins'][iou_bin][index]['init_image']\n",
    "R_init = frames_info['frames']['init_frames_iou_bins'][iou_bin][index]['R_init']\n",
    "t_init = frames_info['frames']['init_frames_iou_bins'][iou_bin][index]['T_init']\n",
    "\n",
    "cam_info_init = CameraInfo(uid=0, R=R_init, T=t_init, FovY=FovY, FovX=FovX, image=image_gt,\n",
    "                        image_path=image_path, image_name=image_name, width=width,\n",
    "                        height=height, qvec = None, cx = cx, cy = cy)\n",
    "\n",
    "iou_value = frames_info['frames']['init_frames_iou_bins'][iou_bin][index]['iou']\n",
    "black_pixels_ratio = frames_info['frames']['init_frames_iou_bins'][iou_bin][index]['black_pixels_ratio']\n",
    "init_outside = True if black_pixels_ratio > 0.3 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = solve_func(cam_info_init=cam_info_init, task_info=task_info, gaussians=gaussians, solving_args=solving_args)\n",
    "\n",
    "output_result = copy.copy(task_info)\n",
    "output_result['image_original_path'] = frames_info['frames']['img_path']\n",
    "output_result['width_original'] = frames_info['frames']['width']\n",
    "output_result['height_original'] = frames_info['frames']['height']\n",
    "output_result['cx_original'] = frames_info['frames']['cx']\n",
    "output_result['cy_original'] = frames_info['frames']['cy']\n",
    "output_result['FovX'] = frames_info['frames']['FovX']\n",
    "output_result['FovY'] = frames_info['frames']['FovY']\n",
    "\n",
    "output_result['R_gt'] = frames_info['frames']['R']\n",
    "output_result['t_gt'] = frames_info['frames']['T']\n",
    "output_result['qvec_gt'] = frames_info['frames']['qvec']\n",
    "output_result['iou_value'] = iou_value\n",
    "\n",
    "output_result = output_result | result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,3, figsize = (15,5))\n",
    "axarr[0].imshow((result['image_init']))\n",
    "axarr[1].imshow((result['image_result']))\n",
    "axarr[2].imshow(result['image_gt'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs102",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
